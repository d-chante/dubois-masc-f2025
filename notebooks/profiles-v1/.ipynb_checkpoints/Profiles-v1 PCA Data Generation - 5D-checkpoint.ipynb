{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598963e9-798a-4b65-b540-8520e008010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# * * * * * * * * * * * * * * * *\n",
    "# Configuration\n",
    "# * * * * * * * * * * * * * * * *\n",
    "DATASET_DIR = '/workspace/datasets'\n",
    "OUTPUT_DIR = '/workspace/outputs'\n",
    "\n",
    "DEVICE= 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f91b7-098d-4a59-abf8-d1afdb86f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from itertools import combinations\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "from lunar_vae import VAE, train, SampleLatentSpace, VisualizeLatentSpace\n",
    "from utils import (\n",
    "    GenerateDensityPlot,\n",
    "    LoadTemperatureDataV1\n",
    ")\n",
    "\n",
    "# * * * * * * * * * * * * * * * *\n",
    "# Setting Variables\n",
    "# * * * * * * * * * * * * * * * *\n",
    "INPUT_CSV_PATH = os.path.join(DATASET_DIR, f'profiles-v1', f'profiles-v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e5547-1b59-4da3-97c8-106f6b57314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# * * * * * * * * * * * * * * * *\n",
    "# Load Temp Data\n",
    "# * * * * * * * * * * * * * * * *\n",
    "temp_data = LoadTemperatureDataV1(INPUT_CSV_PATH, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed51141-9b0e-4c97-8e1a-cac1003cab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# * * * * * * * * * * * * * * * *\n",
    "# Filter In-Range (50 - 450 K)\n",
    "# * * * * * * * * * * * * * * * *\n",
    "mask = (temp_data >= 50) & (temp_data <= 425)\n",
    "valid_rows_mask = mask.all(dim=1)\n",
    "\n",
    "temp_data = temp_data[valid_rows_mask]\n",
    "temp_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0cca14-c46c-43b6-af86-c44ffc89c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# * * * * * * * * * * * * * * * *\n",
    "# Convert to numpy\n",
    "# * * * * * * * * * * * * * * * *\n",
    "temp_data_np = temp_data.numpy() \n",
    "\n",
    "# * * * * * * * * * * * * * * * *\n",
    "# Setting Up for PCA\n",
    "# * * * * * * * * * * * * * * * *\n",
    "n_components = 10\n",
    "batch_size = 100_000\n",
    "\n",
    "# * * * * * * * * * * * * * * * *\n",
    "# Standardize data\n",
    "# * * * * * * * * * * * * * * * *\n",
    "scaler = StandardScaler()\n",
    "temp_data_scaled = scaler.fit_transform(temp_data_np)\n",
    "\n",
    "# * * * * * * * * * * * * * * * *\n",
    "# PCA Fitting\n",
    "# * * * * * * * * * * * * * * * *\n",
    "n_samples = temp_data_scaled.shape[0]\n",
    "n_batches = n_samples // batch_size + int(n_samples % batch_size != 0)\n",
    "\n",
    "ipca = IncrementalPCA(n_components=n_components)\n",
    "\n",
    "print(\"Fitting IncrementalPCA...\")\n",
    "for i in tqdm(range(n_batches), desc=\"Fitting\"):\n",
    "    start = i * batch_size\n",
    "    end = min((i + 1) * batch_size, n_samples)\n",
    "    batch = temp_data_scaled[start:end]\n",
    "    ipca.partial_fit(batch)\n",
    "\n",
    "X_pca = np.zeros((n_samples, n_components))\n",
    "\n",
    "print(\"Transforming with IncrementalPCA...\")\n",
    "for i in tqdm(range(n_batches), desc=\"Transforming\"):\n",
    "    start = i * batch_size\n",
    "    end = min((i + 1) * batch_size, n_samples)\n",
    "    batch = temp_data_scaled[start:end]\n",
    "    X_pca[start:end] = ipca.transform(batch)\n",
    "\n",
    "# * * * * * * * * * * * * * * * *\n",
    "# Plot Variance \n",
    "# * * * * * * * * * * * * * * * *\n",
    "# Plot variance explained\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(range(1, n_components + 1), ipca.explained_variance_ratio_, alpha=0.7)\n",
    "plt.ylabel(\"Explained Variance Ratio\")\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.title(\"PCA Explained Variance\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# * * * * * * * * * * * * * * * *\n",
    "# Pair-wise Plots\n",
    "# * * * * * * * * * * * * * * * *\n",
    "pcs = X_pca[:, :n_components]\n",
    "pairs = list(combinations(range(n_components), 2))\n",
    "\n",
    "n_pairs = len(pairs)\n",
    "cols = 5  \n",
    "rows = (n_pairs + cols - 1) // cols  \n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4), squeeze=False)\n",
    "\n",
    "for idx, (x_idx, y_idx) in enumerate(pairs):\n",
    "    row = idx // cols\n",
    "    col = idx % cols\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    hb = ax.hexbin(pcs[:, x_idx], pcs[:, y_idx], gridsize=50, cmap='viridis', bins='log')\n",
    "    ax.set_xlabel(f\"PC{x_idx + 1}\")\n",
    "    ax.set_ylabel(f\"PC{y_idx + 1}\")\n",
    "    ax.set_title(f\"PCA Density: PC{x_idx + 1} vs PC{y_idx + 1}\")\n",
    "    ax.grid(True)\n",
    "    \n",
    "    cb = fig.colorbar(hb, ax=ax, shrink=0.7)\n",
    "    cb.set_label('log(count)')\n",
    "\n",
    "for idx in range(n_pairs, rows * cols):\n",
    "    fig.delaxes(axes.flatten()[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# * * * * * * * * * * * * * * * *\n",
    "# Scree Plot\n",
    "# * * * * * * * * * * * * * * * *\n",
    "explained_var_ratio = ipca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_var_ratio)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(cumulative_variance)+1), cumulative_variance, marker='o')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% threshold')\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"PCA Explained Variance\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ed1c4-0b57-4e34-921c-e54c37fc20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# * * * * * * * * * * * * * * * *\n",
    "# Re-Do with Optimal n_components\n",
    "# * * * * * * * * * * * * * * * *\n",
    "n_components = 5\n",
    "\n",
    "# * * * * * * * * * * * * * * * *\n",
    "# PCA Fitting\n",
    "# * * * * * * * * * * * * * * * *\n",
    "n_samples = temp_data_scaled.shape[0]\n",
    "n_batches = n_samples // batch_size + int(n_samples % batch_size != 0)\n",
    "\n",
    "ipca = IncrementalPCA(n_components=n_components)\n",
    "\n",
    "print(\"Fitting IncrementalPCA...\")\n",
    "for i in tqdm(range(n_batches), desc=\"Fitting\"):\n",
    "    start = i * batch_size\n",
    "    end = min((i + 1) * batch_size, n_samples)\n",
    "    batch = temp_data_scaled[start:end]\n",
    "    ipca.partial_fit(batch)\n",
    "\n",
    "X_pca = np.zeros((n_samples, n_components))\n",
    "\n",
    "print(\"Transforming with IncrementalPCA...\")\n",
    "for i in tqdm(range(n_batches), desc=\"Transforming\"):\n",
    "    start = i * batch_size\n",
    "    end = min((i + 1) * batch_size, n_samples)\n",
    "    batch = temp_data_scaled[start:end]\n",
    "    X_pca[start:end] = ipca.transform(batch)\n",
    "\n",
    "# * * * * * * * * * * * * * * * *\n",
    "# Plot Variance \n",
    "# * * * * * * * * * * * * * * * *\n",
    "# Plot variance explained\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(range(1, n_components + 1), ipca.explained_variance_ratio_, alpha=0.7)\n",
    "plt.ylabel(\"Explained Variance Ratio\")\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.title(\"PCA Explained Variance\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# * * * * * * * * * * * * * * * *\n",
    "# Pair-wise Plots\n",
    "# * * * * * * * * * * * * * * * *\n",
    "pcs = X_pca[:, :n_components]\n",
    "pairs = list(combinations(range(n_components), 2))\n",
    "\n",
    "n_pairs = len(pairs)\n",
    "cols = 5  \n",
    "rows = (n_pairs + cols - 1) // cols  \n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4), squeeze=False)\n",
    "\n",
    "for idx, (x_idx, y_idx) in enumerate(pairs):\n",
    "    row = idx // cols\n",
    "    col = idx % cols\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    hb = ax.hexbin(pcs[:, x_idx], pcs[:, y_idx], gridsize=50, cmap='viridis', bins='log')\n",
    "    ax.set_xlabel(f\"PC{x_idx + 1}\")\n",
    "    ax.set_ylabel(f\"PC{y_idx + 1}\")\n",
    "    ax.set_title(f\"PCA Density: PC{x_idx + 1} vs PC{y_idx + 1}\")\n",
    "    ax.grid(True)\n",
    "    \n",
    "    cb = fig.colorbar(hb, ax=ax, shrink=0.7)\n",
    "    cb.set_label('log(count)')\n",
    "\n",
    "for idx in range(n_pairs, rows * cols):\n",
    "    fig.delaxes(axes.flatten()[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b431a2eb-37ac-49c5-a98a-829c9f86f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# * * * * * * * * * * * * * * * *\n",
    "# Samples from 5D PCA space\n",
    "# * * * * * * * * * * * * * * * *\n",
    "#sample_sizes = [25, 50, 75, 100, 250, 500]\n",
    "sample_sizes = [100]\n",
    "grid_size = 10  # 10 bins per PC = 100,000 total possible cells in 5D\n",
    "\n",
    "n_dims = 5  # PC1 to PC5\n",
    "\n",
    "for sample_size in sample_sizes:\n",
    "    max_samples_per_cell = sample_size\n",
    "\n",
    "    # Define bin edges for each PC dimension\n",
    "    bins = [np.linspace(X_pca[:, i].min(), X_pca[:, i].max(), grid_size + 1) for i in range(n_dims)]\n",
    "\n",
    "    # Digitize across all 5 dimensions\n",
    "    digitized = [np.digitize(X_pca[:, i], bins[i]) - 1 for i in range(n_dims)]\n",
    "    grid_keys = list(zip(*digitized))  # Each key is a 5D cell ID\n",
    "\n",
    "    # Group indices by grid cell\n",
    "    cell_to_indices = defaultdict(list)\n",
    "    for idx, cell in enumerate(grid_keys):\n",
    "        if all(0 <= cell[d] < grid_size for d in range(n_dims)):\n",
    "            cell_to_indices[cell].append(idx)\n",
    "\n",
    "    total_points = sum(len(indices) for indices in cell_to_indices.values())\n",
    "    balanced_indices = []\n",
    "\n",
    "    # Sample from each non-empty cell\n",
    "    for cell, indices in cell_to_indices.items():\n",
    "        proportion = len(indices) / total_points\n",
    "        samples = min(int(proportion * total_points), max_samples_per_cell)\n",
    "        if samples > 0:\n",
    "            selected = np.random.choice(indices, samples, replace=False)\n",
    "            balanced_indices.extend(selected)\n",
    "\n",
    "    balanced_indices = np.array(balanced_indices)\n",
    "    X_balanced = X_pca[balanced_indices]\n",
    "\n",
    "    print(f\"Final balanced sample size: {X_balanced.shape[0]}\")\n",
    "\n",
    "    # * * * * * * * * * * * * * * * *\n",
    "    # Visualize Sampled Data PCA\n",
    "    # * * * * * * * * * * * * * * * *\n",
    "    pcs_balanced = X_balanced[:, :n_components]\n",
    "    pairs = list(combinations(range(n_components), 2))\n",
    "\n",
    "    n_pairs = len(pairs)\n",
    "    cols = 5\n",
    "    rows = (n_pairs + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4), squeeze=False)\n",
    "\n",
    "    for idx, (x_idx, y_idx) in enumerate(pairs):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        hb = ax.hexbin(pcs_balanced[:, x_idx], pcs_balanced[:, y_idx],\n",
    "                       gridsize=50, cmap='plasma', bins='log')\n",
    "        ax.set_xlabel(f\"PC{x_idx + 1}\")\n",
    "        ax.set_ylabel(f\"PC{y_idx + 1}\")\n",
    "        ax.set_title(f\"PCA Density: PC{x_idx + 1} vs PC{y_idx + 1} (Balanced)\")\n",
    "        ax.grid(True)\n",
    "\n",
    "        cb = fig.colorbar(hb, ax=ax, shrink=0.7)\n",
    "        cb.set_label('log(count)')\n",
    "\n",
    "    for idx in range(n_pairs, rows * cols):\n",
    "        fig.delaxes(axes.flatten()[idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # * * * * * * * * * * * * * * * *\n",
    "    # Visualize Sampled Data Density\n",
    "    # * * * * * * * * * * * * * * * *\n",
    "    temp_balanced_standardized = temp_data_scaled[balanced_indices]\n",
    "    temp_balanced_unscaled = scaler.inverse_transform(temp_balanced_standardized)\n",
    "\n",
    "    temp_tensor = torch.from_numpy(temp_balanced_unscaled).float()\n",
    "    print(\"Balanced sample shape (original scale):\", temp_tensor.shape)\n",
    "\n",
    "    GenerateDensityPlot(temp_tensor, \"/workspace/\")\n",
    "\n",
    "    torch_filename = f\"/workspace/datasets/profiles-v1/profiles-v1-pca-5d/profiles-v1-pca-5-sample-{sample_size}-5d.pt\"\n",
    "    torch.save(temp_tensor, torch_filename)\n",
    "    print(f\"Saved {torch_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
